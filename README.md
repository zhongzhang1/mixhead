# mixhead
Main code for the paper "Mixhead: Breaking The Low-Rank Bottleneck in Multi-Head Attention Language Models"

Replace the multihead_attention.py of fairseq(https://github.com/pytorch/fairseq/tree/main/fairseq/modules).
